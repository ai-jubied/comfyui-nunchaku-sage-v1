# âš¡ Ultimate ComfyUI: SageAttention & Nunchaku

**The Fastest ComfyUI Template on RunPod.**
*4-Bit Quantized Models â€¢ SageAttention 2.0 â€¢ LoRA Training â€¢ Zero Setup*

---

## ğŸš€ Overview

Experience **ultra-low latency** AI image and video generation with the most advanced acceleration stack available. This template combines **SageAttention 2.0** (up to 3x faster than FlashAttention2) with **Nunchaku** (MIT-HAN-LAB's 4-bit inference engine) to deliver maximum performance on NVIDIA GPUs.

Built for **FLUX.1**, **Stable Diffusion 3.5**, **SDXL**, **HunyuanVideo**, **WanVideo**, and the latest quantized models â€” all pre-configured and ready to generate in minutes.

---

## âœ¨ Key Technologies

### ğŸ”¥ SageAttention 2.0
Ultra-efficient attention kernels using INT4/INT8/FP8 quantization with matrix smoothing.

*   **3x faster** than FlashAttention2 on Ada Lovelace (RTX 4090)
*   **4.5x faster** than xformers
*   Negligible quality loss across image, video, and language models
*   Pre-built wheels included for **sm86** (A40, RTX 3090), **sm89** (RTX 4090, L40), and **sm120** (Blackwell)

### âš”ï¸ Nunchaku v1.2 (SVDQuant)
MIT-HAN-LAB's 4-bit inference engine â€” [ICLR 2025 Spotlight paper](http://arxiv.org/abs/2411.05007).

*   **2â€“3x speedup** with 4-bit quantized diffusion models
*   Multi-LoRA and ControlNet support
*   Auto-detects GPU architecture and installs matching wheel

**Supported 4-Bit Models:**

| Model | Type | Notes |
|-------|------|-------|
| FLUX.1-dev | Text-to-Image | 4-bit quantized, LoRA compatible |
| FLUX.1-Kontext | Image Editing | Context-aware generation |
| Qwen-Image | Text-to-Image | Including Lightning variants |
| Qwen-Image-Edit | Image Editing | 4/8-step lightning models |
| Z-Image-Turbo | Text-to-Image | 20â€“30% perf boost in v1.2 |
| SDXL / SDXL-Turbo | Text-to-Image | "SDXL-like speed" on 4-bit models |

### ğŸ’ AI Toolkit (Ostris)
Professional LoRA training directly in your browser â€” no CLI needed.

*   Train LoRAs for **FLUX**, **SD 3.5**, **SDXL**, **Wan 2.2**, and more
*   Configurable quantization (8-bit, 6-bit, 4-bit) for low-VRAM training
*   Slider LoRA training (prompt-only, no dataset required)
*   Built-in dataset management, job monitoring, and sample previews

---

## ğŸ¬ Supported Workflows

| Workflow | Models | Status |
|----------|--------|--------|
| **Text-to-Image** | FLUX.1, SD 3.5, SDXL, Qwen-Image, Z-Image | âœ… Ready |
| **Image-to-Image** | FLUX.1-Kontext, Qwen-Image-Edit | âœ… Ready |
| **Text-to-Video** | WanVideo 2.1/2.2 (14B & 1.3B), HunyuanVideo | âœ… Ready |
| **Image-to-Video** | WanVideo I2V, HunyuanVideo I2V | âœ… Ready |
| **LoRA Training** | FLUX, SD 3.5, SDXL, Wan 2.2 | âœ… Ready |
| **4-Bit Inference** | All Nunchaku quantized models | âœ… Ready |

---

## ğŸ–¥ï¸ Recommended GPUs

| GPU | VRAM | Architecture | SageAttention | Nunchaku | Best For |
|-----|------|-------------|---------------|----------|----------|
| **A40** | 48 GB | Ampere (sm86) | âœ… 2.2.0 | âœ… INT4 | Training + Inference |
| **RTX 4090** | 24 GB | Ada (sm89) | âœ… 2.2.0 | âœ… INT4 | Fast image gen |
| **RTX 3090** | 24 GB | Ampere (sm86) | âœ… 2.2.0 | âœ… INT4 | Budget option |
| **L40 / L40S** | 48 GB | Ada (sm89) | âœ… 2.2.0 | âœ… INT4 | Enterprise workloads |
| **A100** | 80 GB | Ampere (sm80) | âœ… pip | âœ… INT4 | Large models + video |
| **H100** | 80 GB | Hopper (sm90) | âœ… pip | âœ… INT4/FP4 | Maximum throughput |

---

## ğŸ”Œ Service Ports

| Port | Service | Description |
|------|---------|-------------|
| **8188** | ComfyUI | Main generation interface |
| **8888** | JupyterLab | System admin & terminal |
| **8080** | FileBrowser | Upload/download models easily |
| **8675** | AI Toolkit | LoRA training browser UI |

---

## ğŸ› ï¸ Pre-Installed Custom Nodes

| Node | Purpose |
|------|---------|
| âœ… [ComfyUI-Manager](https://github.com/Comfy-Org/ComfyUI-Manager) | Install, update, and manage all custom nodes |
| âœ… [ComfyUI-Crystools](https://github.com/crystian/ComfyUI-Crystools) | GPU/CPU monitoring, metadata, debugging |
| âœ… [ComfyUI-nunchaku](https://github.com/nunchaku-ai/ComfyUI-nunchaku) | 4-bit quantized model inference (SVDQuant) |
| âœ… [HuggingFace Downloader](https://github.com/jnxmx/ComfyUI_HuggingFace_Downloader) | One-click model downloads from HF |
| âœ… [Civicomfy](https://github.com/MoonGoblinDev/Civicomfy) | Civitai model browser & downloader |

---

## âš¡ Quick Start

1.  **Deploy** on RunPod with an A40, RTX 4090, or other supported GPU.
2.  **Wait** for setup (~3â€“5 min first boot). A live progress page shows each stage.
3.  **Launch** via Connect â†’ HTTP Service (Port 8188).
4.  **Upload** your checkpoints using FileBrowser (Port 8080) or HuggingFace Downloader.
5.  **Generate** immediately â€” SageAttention and Nunchaku are pre-configured.

### Optional Environment Variables

| Variable | Description | Example |
|----------|-------------|---------|
| `HF_TOKEN` | HuggingFace access token for gated models | `hf_xxxxx` |
| `CIVITAI_TOKEN` | Civitai API token for model downloads | `xxxxx` |
| `COMFYUI_BACKUP` | HF repo for backup/restore | `user/my-backup` |
| `RESTORE_BACKUP` | Enable first-boot restore | `1` |
| `NUNCHAKU_VERSION` | Override Nunchaku engine version | `1.2.1` |

---

## ğŸ“‚ Persistent Storage

Everything in `/workspace` survives pod restarts:

```
/workspace/
â”œâ”€â”€ ComfyUI/           # ComfyUI installation
â”‚   â”œâ”€â”€ models/        # All checkpoints, LoRAs, VAEs
â”‚   â”œâ”€â”€ custom_nodes/  # All custom nodes
â”‚   â”œâ”€â”€ output/        # Generated images and videos
â”‚   â””â”€â”€ venv/          # Python virtual environment
â””â”€â”€ ai-toolkit/        # AI Toolkit installation
    â”œâ”€â”€ repo/           # Source code
    â””â”€â”€ venv/           # Isolated Python environment
```

---

## ğŸ—ï¸ Technical Stack

| Component | Version |
|-----------|---------|
| Base Image | `nvidia/cuda:12.6.1-cudnn-devel-ubuntu22.04` |
| Python | 3.12 |
| PyTorch | 2.x (CUDA 12.4) |
| Node.js | 22.22.0 LTS |
| SageAttention | 2.2.0 |
| Nunchaku | 1.2.1 |
| ComfyUI | Latest (auto-updated) |

---

> *Maintained by [aijubied](https://github.com/ai-jubied) â€¢ Built for the Community*
